{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrgRgVHI7kHTy7q8gDvGd6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeBrave-BeHumble/Coding_test/blob/main/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC_2%ED%9A%8C%EC%8B%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hICMKG70TBu4"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jun 24 21:21:28 2022\n",
        "\n",
        "@author: FullSun\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#---------------------------------------------\n",
        "#               작업형 제 1유형\n",
        "#---------------------------------------------\n",
        "\n",
        "#----------- [1-1] -----------#\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/boston_housing.csv\")\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data['crim'].sort_values(ascending = False).iloc[9]) # 25.9406\n",
        "data[data['crim'] > 25.9406 ] = 25.9406\n",
        "print(data['crim'].sort_values(ascending = False).head(12))\n",
        "print(data[data['age'] >= 80][['crim','age']])\n",
        "print(data[data['age'] >= 80]['crim'].mean())\n",
        "\n",
        "# 최종코드\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/boston_housing.csv\")\n",
        "# print(data['crim'].sort_values(ascending = False).iloc[9]) # 25.9406\n",
        "data[data['crim'] > 25.9406 ] = 25.9406\n",
        "kk = pd.DataFrame(data['crim'].sort_values(ascending=False)).reset_index(drop=True).rename(columns={'crim':'kk'})\n",
        "data = pd.concat([data, kk], axis=1)\n",
        "print(data[data['age'] >= 80]['kk'].mean())\n",
        "\n",
        "data[data['age'] >= 80]\n",
        "\n",
        "### 5.063482715517241\n",
        "\n",
        "import pandas as pd\n",
        "print(data.sort_values(by='crim', ascending=False))\n",
        "data_sort=data.sort_values(by='crim', ascending=False)\n",
        "print(data_sort.head(12))\n",
        "\n",
        "def recode(series):\n",
        "    if series>=25.9406:\n",
        "        return 25.9406\n",
        "    else:\n",
        "        return series\n",
        "\n",
        "data_sort['re_crim']=data_sort['crim'].apply(recode)\n",
        "# print(data_sort.head(20))\n",
        "\n",
        "data_80 = data_sort[data_sort['age'] >=80]\n",
        "# print(data_80.head(50))\n",
        "print(data_80['re_crim'].mean())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------- [1-2] -----------#\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/california_housing.csv\")\n",
        "print(data.info())\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(help(train_test_split))\n",
        "print(20640*0.8)\n",
        "print(data.iloc[:16512,:].shape)\n",
        "train = data.iloc[:16512,:]\n",
        "test = data.iloc[16512:,:]\n",
        "std_origin = train['total_bedrooms'].std()\n",
        "median_origin = train['total_bedrooms'].median()\n",
        "std_new = train['total_bedrooms'].fillna(median_origin).std()\n",
        "print(abs(std_origin - std_new))\n",
        "\n",
        "# 최종코드\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/california_housing.csv\")\n",
        "# print(20640*0.8)\n",
        "train = data.iloc[:16512,:]\n",
        "# test = data.iloc[16512:,:]\n",
        "std_origin = train['total_bedrooms'].std()\n",
        "median_origin = train['total_bedrooms'].median()\n",
        "std_new = train['total_bedrooms'].fillna(median_origin).std()\n",
        "print(abs(std_origin - std_new))\n",
        "### 1.9751472916456692\n",
        "\n",
        "\n",
        "#----------- [1-3] -----------#\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/insurance.csv\")\n",
        "print(data.describe())\n",
        "upper_bound = ( data['charges'].mean() ) + 1.5*( data['charges'].std() )\n",
        "lower_bound = ( data['charges'].mean() ) - 1.5*( data['charges'].std() )\n",
        "upper = data[data['charges'] > upper_bound ]\n",
        "lower = data[data['charges'] < lower_bound ]\n",
        "final = pd.concat([upper, lower], axis = 0)\n",
        "print(final['charges'].sum()) # 6421430.0206699995\n",
        "print(upper.head(5), '\\n', '='*30, '\\n', lower.head(5))\n",
        "\n",
        "# 최종코드\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/insurance.csv\")\n",
        "upper_bound = ( data['charges'].mean() ) + 1.5*( data['charges'].std() )\n",
        "lower_bound = ( data['charges'].mean() ) - 1.5*( data['charges'].std() )\n",
        "upper = data[data['charges'] > upper_bound ]\n",
        "lower = data[data['charges'] < lower_bound ]\n",
        "final = pd.concat([upper, lower], axis = 0)\n",
        "print(final['charges'].sum())\n",
        "### 6421430.0206699995\n",
        "\n",
        "\n",
        "#---------------------------------------------\n",
        "#               작업형 제 2유형\n",
        "#---------------------------------------------\n",
        "import pandas as pd\n",
        "X_train = pd.read_csv(\"C:/Users/2회 실기/X_train.csv\")\n",
        "X_test = pd.read_csv(\"C:/Users/2회 실기/X_test.csv\")\n",
        "y_train = pd.read_csv(\"C:/Users/2회 실기/y_train.csv\")\n",
        "print(X_train.shape, X_test.shape, y_train.shape) # (8799, 11) (2200, 11) (8799, 2)\n",
        "print(X_train.head(5).T)\n",
        "print(X_train.describe().T) # 딱히 단위가 커보인다거나 이상값 없어보임\n",
        "''' Warehouse_block : A,B,C,D,E\n",
        "    Mode_of_Shipment : Ship  Flight\n",
        "    Product_importance : high  medium     low\n",
        "    Gender  : F       M \n",
        "'''   \n",
        "print(X_train.info()) # 결측치 X\n",
        "print(X_train['Warehouse_block'].unique(), '\\n', # ['B' 'F' 'C' 'A' 'D'] \n",
        "      X_train['Mode_of_Shipment'].unique(), '\\n', # ['Ship' 'Flight' 'Road'] \n",
        "      X_train['Product_importance'].unique(), '\\n', #  ['high' 'medium' 'low'] \n",
        "      X_train['Gender'].unique(), '\\n', #  ['F' 'M'] \n",
        "      X_train['Customer_rating'].unique()) #  [4 3 1 5 2]\n",
        "# 코딩오류 X\n",
        "\n",
        "# 필요없는 행 제외\n",
        "X_test_ID = X_test['ID']\n",
        "X_test = X_test.drop(columns = ['ID'])\n",
        "X_train = X_train.drop(columns = ['ID'])\n",
        "y_train_ID = y_train['ID']\n",
        "y_train = y_train.drop(columns = ['ID'])\n",
        "\n",
        "# 범주형 변수\n",
        "# 분포 확인\n",
        "data = pd.concat([X_train, y_train], axis=1)\n",
        "print(data.groupby(['Warehouse_block'])['Reached.on.Time_Y.N'].count(), '\\n', \n",
        "      data.groupby(['Mode_of_Shipment'])['Reached.on.Time_Y.N'].count(), '\\n', \n",
        "      data.groupby(['Product_importance'])['Reached.on.Time_Y.N'].count(), '\\n', \n",
        "      data.groupby(['Gender'])['Reached.on.Time_Y.N'].count(), '\\n', \n",
        "      data.groupby(['Customer_rating'])['Reached.on.Time_Y.N'].count()) \n",
        "''' 1번 변수-> F가 유독 많음\n",
        "    2번 변수-> ship\n",
        "    3번변수->high 가 적음\n",
        "    성별.. 지워도 될 듯?\n",
        "    customer도 지워도 될 듯 ''' \n",
        "X_train = X_train.drop(columns = ['Gender', 'Customer_rating'])    \n",
        "X_test = X_test.drop(columns = ['Gender', 'Customer_rating'])    \n",
        "    \n",
        "X_train_backup = X_train\n",
        "X_test_backup = X_test\n",
        "\n",
        "# 원핫 인코딩\n",
        "from pandas import get_dummies\n",
        "\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "print(X_train.head(3).T)\n",
        "X_train, X_test = X_test.align(X_test, join='inner')\n",
        "X_train_cate = X_train.iloc[:, 5:]\n",
        "X_test_cate = X_test.iloc[:, 5:]\n",
        "\n",
        "# 연속형 변수\n",
        "# 이상값 처리\n",
        "upper = X_train['Weight_in_gms'].mean() + 1.5*X_train['Weight_in_gms'].std()\n",
        "under = X_train['Weight_in_gms'].mean() - 1.5*X_train['Weight_in_gms'].std()\n",
        "\n",
        "condition1 = X_train['Weight_in_gms'] > upper\n",
        "X_train.loc[condition1, 'Weight_in_gms'] = upper\n",
        "condition2 = X_train['Weight_in_gms'] < under\n",
        "X_train.loc[condition2, 'Weight_in_gms'] = under\n",
        "\n",
        "condition1 = X_test['Weight_in_gms'] > upper\n",
        "X_test.loc[condition1, 'Weight_in_gms'] = upper\n",
        "condition2 = X_test['Weight_in_gms'] < under\n",
        "X_test.loc[condition2, 'Weight_in_gms'] = under\n",
        "\n",
        "# 스케일링\n",
        "X_train_conti = X_train.iloc[:,:5]\n",
        "X_test_conti = X_test.iloc[:, :5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_conti = pd.DataFrame(scaler.fit_transform(X_train_conti), columns=X_train_conti.columns)\n",
        "print(X_train_conti.describe().T)\n",
        "X_test_conti = pd.DataFrame(scaler.transform(X_test_conti), columns=X_test_conti.columns)\n",
        "\n",
        "# 상관분석\n",
        "print(data[['Customer_care_calls', 'Cost_of_the_Product',\n",
        "               'Prior_purchases', 'Discount_offered', 'Weight_in_gms',\n",
        "               'Reached.on.Time_Y.N']].corr())\n",
        "# 딱히 높은 상관 없음\n",
        "\n",
        "# data sum\n",
        "X_train = pd.concat([X_train_conti, X_train_cate], axis=1)\n",
        "X_test = pd.concat([X_test_conti, X_test_cate], axis=1)\n",
        "print(X_train.head(5).T)\n",
        "X_train_backup = X_train\n",
        "X_test_backup = X_test\n",
        "\n",
        "# 데이터 스플릿\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train, y_train,\n",
        "                                                      test_size=0.2, random_state=66,\n",
        "                                                      stratify=y_train)\n",
        "print(X_train1.shape, X_val1.shape, y_train1.shape, y_val1.shape)\n",
        "\n",
        "# 모델링 및 평가\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model1 = XGBClassifier(n_estimators=100, max_depth=3, random_state=66)\n",
        "model2 = XGBClassifier(n_estimators=200, max_depth=5, random_state=66)\n",
        "model3 = RandomForestClassifier(n_estimators=100, criterion='entropy',\n",
        "                                random_state=66)\n",
        "model4 = RandomForestClassifier(n_estimators=200, criterion='gini',\n",
        "                                random_state=66)\n",
        "\n",
        "print(help(XGBClassifier))\n",
        "\n",
        "model1.fit(X_train1, y_train1)\n",
        "model2.fit(X_train1, y_train1)\n",
        "model3.fit(X_train1, y_train1)\n",
        "model4.fit(X_train1, y_train1)\n",
        "\n",
        "y_val_pred1 = pd.DataFrame(model1.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "y_val_pred2 = pd.DataFrame(model2.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "y_val_pred3 = pd.DataFrame(model3.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "y_val_pred4 = pd.DataFrame(model4.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, r2_score, accuracy_score \n",
        "print(roc_auc_score(y_val1, y_val_pred1),'\\n',\n",
        "      roc_auc_score(y_val1, y_val_pred2),'\\n',\n",
        "      roc_auc_score(y_val1, y_val_pred2),'\\n',\n",
        "      roc_auc_score(y_val1, y_val_pred2))\n",
        "\n",
        "# 모형 개선\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "roc_list = []\n",
        "\n",
        "for a in range(99,115):\n",
        "    X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train, y_train,\n",
        "                                                      test_size=0.2, stratify=y_train,\n",
        "                                                      random_state=a)\n",
        "    \n",
        "    model1 = XGBClassifier(n_estimators=100, max_depth=3, random_state=66)\n",
        "    model2 = XGBClassifier(n_estimators=200, max_depth=5, random_state=66)\n",
        "    model3 = RandomForestClassifier(max_depth=10, criterion='entropy', random_state=66)\n",
        "    model4 = RandomForestClassifier(max_depth=8, criterion='entropy', random_state=66)\n",
        "\n",
        "    model1.fit(X_train1, y_train1)\n",
        "    model2.fit(X_train1, y_train1)\n",
        "    model3.fit(X_train1, y_train1)\n",
        "    model4.fit(X_train1, y_train1)\n",
        "\n",
        "    y_val_pred1 = pd.DataFrame(model1.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "    y_val_pred2 = pd.DataFrame(model2.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "    y_val_pred3 = pd.DataFrame(model3.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "    y_val_pred4 = pd.DataFrame(model4.predict(X_val1)).rename(columns = {0:'pred'})\n",
        "\n",
        "    roc_auc1 = roc_auc_score(y_val1, y_val_pred1)\n",
        "    roc_auc2 = roc_auc_score(y_val1, y_val_pred2)\n",
        "    roc_auc3 = roc_auc_score(y_val1, y_val_pred3)\n",
        "    roc_auc4 = roc_auc_score(y_val1, y_val_pred4)\n",
        "    \n",
        "    roc_list.append((a, roc_auc1, roc_auc2, roc_auc3, roc_auc4))\n",
        "\n",
        "roc_list.max\n",
        "print(roc_list[0])\n",
        "\n",
        "print(time.time()-start)\n",
        "\n",
        "''' 0일 때 model3 -> 0.72'''\n",
        "\n",
        "tt = pd.DataFrame(roc_list)\n",
        "print(tt[1].max(), tt[2].max(), tt[3].max(), tt[4].argmax())\n",
        "print(tt.iloc[9,:])\n",
        "\n",
        "\n",
        "# 최종 모형\n",
        "X_train1, x_val1, y_train1, y_val1 = train_test_split(X_train, y_train, \n",
        "                                                      random_state=108, stratify=y_train,\n",
        "                                                      test_size=0.2)\n",
        "\n",
        "model = RandomForestClassifier(max_depth=8, criterion='entropy', random_state=66)\n",
        "model.fit(X_train1, y_train1)\n",
        "y_val_pred = pd.DataFrame(model.predict(x_val1)).rename(columns = {0:'pred'})\n",
        "print(roc_auc_score(y_val1, y_val_pred))\n",
        "\n",
        "y_test_pred = pd.DataFrame(model.predict(X_test)).rename(columns={0:'pred'})\n",
        "final = pd.concat([X_test_ID, y_test_pred], axis=1)\n",
        "final.to_csv(\"C:/Users/2회 실기/fin.csv\", index=False)\n",
        "\n",
        "fin = pd.read_csv(\"C:/Users/2회 실기/fin.csv\")\n",
        "print(fin)\n",
        "\n"
      ]
    }
  ]
}