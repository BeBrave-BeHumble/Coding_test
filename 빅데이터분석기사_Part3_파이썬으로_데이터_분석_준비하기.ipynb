{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkNYuUtCSU0NlYg/2XI62K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeBrave-BeHumble/Coding_test/blob/main/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC_Part3_%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_%EC%A4%80%EB%B9%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6NVJPEDKcav"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jun 10 05:55:08 2022\n",
        "\n",
        "@author: FullSun\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "###############################################\n",
        "##### Part3. 파이썬으로 데이터 분석 준비하기 #####\n",
        "###############################################\n",
        "\n",
        "#---------------------------------------------\n",
        "#     1. 실습 데이터와 실행 환경 구성하기\n",
        "#---------------------------------------------\n",
        "\n",
        "#--------- <1.1> 실습 데이터 구성하기 ---------#\n",
        "\n",
        "# 자료 내려받기 : https://github.com/7ieon/bigData\n",
        "\n",
        "\n",
        "#--------- <1-2> 파이썬 실습 환경 구성하기 ---------#\n",
        "\n",
        "# 코랩, 주피터 노트북, 파이참, 스파이더, 비주얼 스튜디오 등 아무거나 선택.\n",
        "# 왜인지.. 스파이더로 해버려서..\n",
        "\n",
        "\n",
        "#--------- <1-3> 실습 데이터 이해하기 ---------#\n",
        "\n",
        "# mtcars: R에서도 자주 쓰이는 데이터. 연비를 나타내는 mpg를 타겟변수로 사용할 것.\n",
        "\n",
        "#---------------------------------------------\n",
        "#        2. 데이터 분석 절차 체득하기\n",
        "#---------------------------------------------\n",
        "''' 데이터 준비하기\n",
        "    > 데이터 관찰하고 가공하기\n",
        "    > 데이터 분리하기 (training, validation, test)\n",
        "    > 학습 및 검증\n",
        "    > 출력 후 저장 '''\n",
        "\n",
        "# 실제 시험 환경에서는 반드시 print() 사용해야 출력 가능!\n",
        "\n",
        "\n",
        "#--------- <2-1> 데이터 준비하기: 데이터 로드 ---------#\n",
        "\n",
        "# 빅데이터 분석기사에서 주어지는 샘플은 2차원 구조이므로, pandas기반으로 분석할 것.\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/mtcars.csv\")\n",
        "print(data.head()) # 일반적인 환경에서는 print() 필요없지만 시험 환경에서는 반드시 쓸 것.\n",
        "# unnamed열과 am열은 문자열\n",
        "\n",
        "\n",
        "##### [1] 데이터 둘러보기\n",
        "\n",
        "## 데이터 모양 확인하기\n",
        "print(data.shape) #32,12\n",
        "\n",
        "## 데이터 타입 확인하기\n",
        "print(type(data)) #DF\n",
        "\n",
        "## 데이터의 열 확인하기\n",
        "print(data.columns)\n",
        "\n",
        "## 기초 통계량 구하기\n",
        "print(data.describe())\n",
        "''' 8 rows x 9 columns를 통해 12개 피처 중 8개 열이 수치형임을 알 수 있음.\n",
        "    cyl(엔진 기통 수)의 max가 50으로 이상치임을 알 수 있음. '''\n",
        "print(data['hp'].describe()) #말 줄임표(...)로 생략된 데이터 정보 보기\n",
        "\n",
        "## 데이터 중복 제외하기\n",
        "print(data['am'].unique())\n",
        "print(data.iloc[:,0].unique())\n",
        "print(data['gear'].unique())\n",
        "print(data['vs'].unique())\n",
        "\n",
        "## 요약 정보 확인하기\n",
        "print(data.info()) #32x12 행렬이며, 결측치 있는 열 2개\n",
        "\n",
        "## 상관관계 구하기\n",
        "print(data.corr())\n",
        "data.corr().iloc[:,4] #생략된 부분 확인하기\n",
        "\n",
        "\n",
        "##### [2] 종속변수와 독립변수 분리하기\n",
        "\n",
        "X = data.drop(columns = 'mpg') # 독립변수\n",
        "Y = data['mpg'] #종속변수\n",
        "print(X.head())\n",
        "print(Y.head())\n",
        "\n",
        "\n",
        "#--------- <2-2> 데이터를 관찰하고 가공하기: 데이터 전처리 ---------#\n",
        "\n",
        "# **빅데이터 분석기사 시험 환경은 시각화가 불가능. 텍스트 기반의 전처리만 가능!!\n",
        "\n",
        "##### [1] 불필요한 열 삭제하기\n",
        "print(X.head()) # 모델명인 Unnamed: 0 열은 연비와 무관하므로 삭제\n",
        "#X.drop(columns = 'Unnamed: 0')\n",
        "X = X.iloc[:, 1:] # Unnamed: 0 열은 첫 번째 열이니까\n",
        "print(X.head())\n",
        "\n",
        "\n",
        "##### [2] 결측값 처리하기\n",
        "\n",
        "''' ** 빅데이터 분석기사에서는 결측치 삭제하면 안 됨!!!!\n",
        "    평균, 중위수로 대치하거나 패턴 파악하여 대치해야 함\n",
        "    그러나 문제에서 삭제하라고 하면 삭제 '''\n",
        "## 결측치 여부 확인하기\n",
        "print(X.isnull().sum())\n",
        "\n",
        "## 평균값으로 대치하기\n",
        "X_cyl_mean = X['cyl'].mean()\n",
        "print(X_cyl_mean)\n",
        "X['cyl'] = X['cyl'].fillna(X_cyl_mean)\n",
        "print(X.isnull().sum())\n",
        "\n",
        "## 중위수로 대치하기\n",
        "X_qsec_median = X['qsec'].median()\n",
        "print(X_qsec_median)\n",
        "X['qsec'] = X['qsec'].fillna(X_qsec_median)\n",
        "print(X.isnull().sum())\n",
        "\n",
        "\n",
        "##### [3] 잘못된 값을 올바르게 바꾸기\n",
        "print(X['gear'].unique()) #*3, *5 코딩오류 때문에 object(문자열)로 인식됨\n",
        "print(X['gear'].replace('*3', '3').replace('*5', '5')) #의도한 바가 맞는지 확인\n",
        "X['gear'] = X['gear'].replace('*3', '3').replace('*5', '5') \n",
        "print(X['gear'].unique())\n",
        "\n",
        "\n",
        "##### [4] 이상값 처리하기\n",
        "''' ** 빅데이터 분석기사에서는 이상값 처리할 때 삭제 말고 대치할 것!!!! '''\n",
        "\n",
        "## 사분위범위 활용하기\n",
        "''' (Q1 - 1.5*IQR)   &    (Q3 + 1.5*IQR) 을 기준으로 한다'''\n",
        "X_describe = X.describe()\n",
        "print(X_describe)\n",
        "print(X_describe.loc['75%'],'\\n', X_describe.loc['25%']) #Q3, Q1\n",
        "X_iqr = X_describe.loc['75%'] - X_describe.loc['25%']\n",
        "\n",
        "# 내가 작성한 답안\n",
        "upperbound = X_describe.loc['75%']+1.5*X_iqr\n",
        "lowerbound = X_describe.loc['25%']-1.5*X_iqr\n",
        "for i in X.columns:\n",
        "    if X[i].dtype != 'O': #string 변수 제외\n",
        "        # max 값이 Q3+1.5IQR 보다 큰 값 => 이상치 존재 \n",
        "        num = X.loc[X[i] > upperbound.loc[i]].index #index 추출  \n",
        "        X.loc[num, i] = upperbound.loc[i] # 대체\n",
        "        # min 값이 Q1-1.5IQR 보다 작은 값 => 이상치 존재\n",
        "        num2 = X.loc[X[i] < lowerbound.loc[i]].index #index 추출\n",
        "        X.loc[num2, i] = lowerbound.loc[i] # 대체\n",
        "\n",
        "X_describe2 = X.describe()\n",
        "print(X_describe['max'],'\\n',X_describe2['max']) #비교\n",
        "print(X_describe['min'],'\\n',X_describe2['min'])\n",
        "\n",
        "# 책에 나온 답안\n",
        "print(X_describe.loc['75%'] + (1.5 * X_iqr))\n",
        "print(X_describe.loc['max']) #X 변수의 최대값 확인\n",
        "# 최대값이 범위를 초과하는 변수: cyl, hp, wt, qsec, carb\n",
        "print(X.loc[X['cyl'] > 14]) #cyl열 값이 14 초과인 index 추출\n",
        "X.loc[14, 'cyl'] = 14 #14번째 행의 cyl값을 14로 대체\n",
        "X.loc[14, 'cyl'] #확인\n",
        "# 나머지 열에 대해서도 위와 같이 진행하나, 일일이 바꿔줘야 한다는 번거로움이 있음.\n",
        "# 데이터의 차원이 커지면 사용하기 어려움.\n",
        "\n",
        "## 평균과 표준편차 활용하기\n",
        "''' mean+-1.5std '''\n",
        "def outlier(data, column):\n",
        "    mean = data[column].mean()\n",
        "    std = data[column].std()\n",
        "    lowest = mean - std*1.5\n",
        "    highest = mean + std*1.5\n",
        "    print('최소 경계값: ', lowest, '최대 경계값: ', highest)\n",
        "    \n",
        "    outlier_index = data[column][ (data[column] < lowest) \\\n",
        "                                 | (data[column] > highest) ].index\n",
        "    return outlier_index    \n",
        "\n",
        "print(outlier(X, 'qsec'))\n",
        "print(X.loc[24,'qsec']) # 인덱스24, 열이 qsec인 값 확인하기\n",
        "X.loc[14,'qsec'] = 42.39618445605777 # 대체\n",
        "print(X.loc[14,'qsec']) # 확인\n",
        "\n",
        "print(outlier(X, 'carb'))\n",
        "print(X.loc[[29,30], 'carb'])\n",
        "X.loc[[29, 30], 'carb'] = 5.235299966447778\n",
        "print(X.loc[[29, 30], 'carb'])\n",
        "\n",
        "\n",
        "##### [5] 데이터를 동일한 범위로 맞추기: 데이터 스케일링\n",
        "''' 머신러닝 결과가 왜곡되지 않고 특정한 동립변수를 무시하지 않도록 하기 위헤\n",
        "    독립변수들의 범위를 동일하게 만드는 작업 '''\n",
        "\n",
        "## 표준 크기 변환: StandardScaler\n",
        "''' 평균값이 0, 표준편차가 1인 정규분포로 변환하는 방법 '''\n",
        "# sklearn 패키지의 preprocessing 모듈에서 StandardScaler 함수 가져오기\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# X변수에서 qsec열만 추출한 후, temp 변수에 저장하기\n",
        "#type(X['qsec']) # 괄호 하나면 시리즈 = 데이터프레임에서 열이 1개\n",
        "type(X[['qsec']]) #괄호 두개여야 데이터 프레임\n",
        "temp = X[['qsec']]\n",
        "\n",
        "# StandardScaler 함수 호출하여 표준 크기변환 기능을 갖는 scaler라는 객체 만들기 \n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 표준 크기변환하는 scaler에게 fit_transform 명령으로 temp 변수의 크기변환 요청하기\n",
        "print(scaler.fit_transform(temp)) # 결과는 array\n",
        "qsec_s_scaler = pd.DataFrame(scaler.fit_transform(temp)) # DF로 전환\n",
        "\n",
        "#qsec_s_scaler의 기초통계 확인하기\n",
        "print(qsec_s_scaler.describe()) # **mean은 0에 근사하며, std는 1에 근사한 것을 알 수 있다!!\n",
        "X['qsec'] = pd.DataFrame(scaler.fit_transform(temp))\n",
        "\n",
        "## 최대 최소 크기변환: MinMaxScaler\n",
        "''' 최소값을 0, 최대값을 1을 가지는 분포로 변환하는 방법.\n",
        "    ** 주로 종속변수가 연속형 범주인 >회귀< 문제에 활용 ** '''\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "temp = X[['qsec']]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "print(scaler.fit_transform(temp))\n",
        "qsec_m_scaler = pd.DataFrame(scaler.fit_transform(temp))\n",
        "\n",
        "print(qsec_m_scaler.describe()) # 최소값 0, 최대값 1\n",
        "X['qsec'] = pd.Dataframe(scaler.fit_transfrom(temp))\n",
        "\n",
        "## 로버스트 크기변환: RobustScaler\n",
        "''' 중앙값이 0, IQR이 1인 분포로 변환하는 방법\n",
        "    ** 이상값의 영향을 잘 받지 않기 때문에 일반적으로 활용 ** '''\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "temp = X[['qsec']]\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "print(scaler.fit_transform(temp))\n",
        "qsec_r_scaler = pd.DataFrame(scaler.fit_transform(temp))\n",
        "print(qsec_r_scaler.describe()) # Q2 = 0 \n",
        "qsec_r_scaler.describe().loc['75%'] - qsec_r_scaler.describe().loc['25%'] #IQR = 1\n",
        "\n",
        "\n",
        "##### [6] 데이터 타입 변경하기\n",
        "''' 데이터의 요약정보를 통해 범주형(object, string)/ 연속형(int64, float64) 확인.\n",
        "    만약 적절하지 못하다면 astype() 함수로 재설정 '''\n",
        "# X 변수의 요약정보 확인\n",
        "print(X.info())\n",
        "X['gear'] #object로 설정되어 있음\n",
        "# gear의 데이터 타입을 int64로 변경한 후 다시 gear에 저장하기\n",
        "X['gear'] = X['gear'].astype('int64')\n",
        "# gear의 데이터 타입 확인\n",
        "X['gear'].dtype\n",
        "\n",
        "\n",
        "##### [7] 범주형을 수치형으로 변경하기: 인코딩(encoding)\n",
        "\n",
        "## 원핫 인코딩: One-Hot Encoding\n",
        "''' 1)pandas의 get_dummies(): 자동으로 범주형 변수만 골라서 인코딩 해줌.\n",
        "    2)sklearn의 OneHotEncoder(): 연속형 변수도 인코딩함.\n",
        "                                객체와 모델을 학습하는 코드를 추가로 작성해야 함.'''\n",
        "print(X.head()) # am열 변환 필요\n",
        "# am열에서 중복 제외한 클래스 알아보기\n",
        "print(X['am'].unique())\n",
        "# 원핫인코딩 수행\n",
        "print(pd.get_dummies(X['am']))\n",
        "''' am의 범주였던 auto와 manual이라는 2개의 새로운 열로 생성됨. 하지만 범주의 수만큼 변수를 생성하는 것은 메모리 낭비.\n",
        "    ** (범주 수 - 1)개만큼 생성하는 것이 좋음   =>   drop_first = True 옵션 사용 '''\n",
        "print(pd.get_dummies(X['am'], drop_first = True)) #manual 열 하나만 생성됨\n",
        "\n",
        "# X의 전체 열을 대상으로 원핫 인코딩 수행한 결과 확인해보기\n",
        "print(X.info())\n",
        "\n",
        "# X 전체를 인코딩하기\n",
        "print(pd.get_dummies(X, drop_first = True)) # am열이 사라지고 am_manual 생성됨\n",
        "\n",
        "## 라벨 인코딩: Label Encoding\n",
        "''' * 라벨 인코딩은 1,2,3 이런 식이라 값의 크고 작음처럼 보일 수 있어서 트리 계열 분석에만 사용\n",
        "    sklearn의 LabelEncoder() '''\n",
        "print(X['am'].head())    \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LabelEncoder 호출을 통해 인코딩 기능을 갖는 encoder 객체 만들기\n",
        "encoder = LabelEncoder()\n",
        "# encoder 통해 am 열 값에 대해 라벨 인코딩 수행\n",
        "print(encoder.fit_transform(X['am'])) # 인코더에 am 넣어서 변환\n",
        "\n",
        "# 세 가지 과일 라벨 인코딩\n",
        "fruit = ['apple', 'banana', 'melon']\n",
        "# LabelEncoder 호출\n",
        "encoder = LabelEncoder()\n",
        "# 인코딩 후 fruit_new로 저장\n",
        "fruit_new = encoder.fit_transform(fruit)\n",
        "# 기존 변수와 비교\n",
        "print(fruit, fruit_new)\n",
        "\n",
        "## 수동 인코딩: Replace\n",
        "''' replace(기존값, 변경값) '''\n",
        "# am열에서 manual은 0으로, auto는 1로 변경 후 am.new에 저장\n",
        "X['am_new'] = X['am'].replace('manual', 0).replace('auto', 1)\n",
        "print(X.head())\n",
        "# 기존의 열은 불필요하므로 삭제\n",
        "X = X.drop(columns = ['am'])\n",
        "print(X.head())\n",
        "\n",
        "\n",
        "##### [8] 파생변수 만들기\n",
        "\n",
        "## wt을 등급에 따라 구분하는 wt_class 만들기\n",
        "# 평균 3.3 기준\n",
        "print(X['wt'] < 3.3) # 3.3보다 작은지 여부\n",
        "# wt가 3.3보다 작은지 condition에 저장\n",
        "condition = X['wt']<3.3\n",
        "# X가 condition조건을 만족하면 wt_class=0\n",
        "X.loc[condition, 'wt_class'] = 0\n",
        "# 그렇지 않으면 wt_class=1\n",
        "X.loc[~condition, 'wt_class'] = 1\n",
        "print(X[['wt', 'wt_class']])\n",
        "# 기존 wt 삭제\n",
        "X = X.drop(columns = ['wt'])\n",
        "print(X.head())\n",
        "\n",
        "## qsec을 (1/4mile 도달 시간) 단위에서 1mile 단위로 변환\n",
        "X['qsec_4'] = X['qsec'] * 4\n",
        "print(X[['qsec', 'qsec_4']])\n",
        "\n",
        "\n",
        "#--------- <2-3> 학습 데이터로 공부하기: 모델 생성과 모델 검증 ---------#\n",
        " # ++ 내 맘대로 데이터 대충 전처리\n",
        "''' import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/mtcars.csv\")\n",
        "print(data.head())\n",
        "data.columns\n",
        "print(data.describe())\n",
        "print(data.describe()['wt'])\n",
        "print(data.info()) #cyl, qsec 결측값 존재\n",
        "data = data.iloc[:, 1:] # Unnamed: 0 열 제거\n",
        "\n",
        "print(data['mpg'].unique())\n",
        "print(data['cyl'].unique()) # nan 존재\n",
        "print(data['vs'].unique()) # binary\n",
        "print(data['am'].unique()) # categorical ['manual' 'auto']\n",
        "print(data['gear'].unique()) # categorical ['4' '3' '*3' '5' '*5']\n",
        "#print(data.columns[-1])\n",
        "print(data['carb'].unique()) # [4 1 2 3 6 8]\n",
        "\n",
        "X = data.drop(columns='mpg') #data.iloc[:, 1:]\n",
        "Y = data['mpg']\n",
        "\n",
        "X['gear'] = X['gear'].replace('*3', '3').replace('*5', '5')\n",
        "\n",
        "X.isnull().sum()\n",
        "cyl_mean = X['cyl'].mean()\n",
        "X['cyl'] = X['cyl'].fillna(cyl_mean)\n",
        "X.isnull().sum()\n",
        "\n",
        "qsec_median = X['qsec'].median()\n",
        "X['qsec'] = X['qsec'].fillna(qsec_median)\n",
        "X.isnull().sum()\n",
        "\n",
        "def outlier(data, column):\n",
        "    mean = data[column].mean()\n",
        "    std = data[column].std()\n",
        "    lowest = mean - 1.5*std\n",
        "    highest = mean + 1.5*std\n",
        "    print('최소경계값:', lowest, '최대경계값:', highest)\n",
        "    outlier_idx = data[column][ (data[column] < lowest) \\\n",
        "                               | (data[column] > highest) ].index\n",
        "    return outlier_idx\n",
        "\n",
        "print( outlier(X, 'qsec') )\n",
        "X.loc[24, 'qsec'] = 42.39618445605777\n",
        "print( outlier(X, 'carb') )\n",
        "X.loc[[29, 30], 'carb'] = 5.235299966447778\n",
        "print(X.describe())\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X['qsec'] = scaler.fit_transform(X[['qsec']]) #df로 넣기\n",
        "\n",
        "X['gear'] = X['gear'].astype('int64')\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True) \n",
        "X = X.rename(columns = {'am_manual':'am_new'}) '''\n",
        "\n",
        "\n",
        "##### [1] 학습 데이터와 테스트 데이터를 분리하기\n",
        "    \n",
        "# 데이터 분리를 위해 model_selection 모듈의 train_test_split 함수 호출\n",
        "from sklearn.model_selection import train_test_split\n",
        "# train, test 셋 분리하기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=10)\n",
        "# 데이터 확인하기\n",
        "print(X_train.head())\n",
        "print(y_train.head())\n",
        "print(X_test.head())\n",
        "print(y_test.head())\n",
        "\n",
        "\n",
        "##### [2] 공부하고 평가하기: 모델링modeling\n",
        "\n",
        "## 모델 학습과 파이썬 코드\n",
        "''' 1) 사용할 모델의 함수 가져오기\n",
        "        from sklearn.모듈 import 함수\n",
        "    2) 학습 모델 만들기\n",
        "        model = 모델함수()\n",
        "    3) 학습 데이터로 모델 학습시키기\n",
        "        model.fit(X_train, y_test)\n",
        "    4) 학습된 모델로 값 예측하기\n",
        "        y_train의 예측값 = model.predict(X_train)\n",
        "        y_test의 예측값 = model.predict(X_test)   '''\n",
        "\n",
        "## 모델 평가와 파이썬 코드\n",
        "''' 1) 평가할 함수 가져오기\n",
        "        from sklearn.metrics import 평가함수\n",
        "    2) 모델 평가하기\n",
        "        print(평가함수(y_train, y_train의 예측값))\n",
        "        print(평가함수(y_test, y_test의 예측값))   '''\n",
        "\n",
        "## 예측 모델링 수행\n",
        "''' 1st) 선형회귀 LinearRegression 적합하기 '''\n",
        "# 선형회귀: linear_model 모듈에서 LinearRegression 모델 가져오기\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# 선형회귀 분석 수행할 기본 모델 만들기\n",
        "model = LinearRegression()\n",
        "# 생성한 모델에 X_train, y_train으로 학습 시키기\n",
        "model.fit(X_train, y_train)\n",
        "# 학습이 완료된 모델에 y_train 값 예측하기\n",
        "y_train_predicted = model.predict(X_train)\n",
        "# 학습이 완료된 모델에 X_test 전달하여 y_test 값 예측하기\n",
        "y_test_predicted = model.predict(X_test)\n",
        "# 선형회귀 모델로 도출된 y 절편(bete0) 구하기\n",
        "print(model.intercept_)\n",
        "# 선형회귀 모델에 포함된 독립변수의 절편 구하기\n",
        "print(model.coef_)\n",
        "\n",
        "''' ** 평가지표\n",
        "    -MAE(Mean Absolute Error): 실제값과 예측값의 차이를 절대값 하여 평균 (0애 가까울 수록 예측 정확도 높음)\n",
        "    -MSE(Mean Squared Error): 실제값과 예측값의 차이를 제곱하여 평균 (0애 가까울 수록 예측 정확도 높음)\n",
        "    -RMSE(Root Mean Squared Error): MSE 제곱근 (0애 가까울 수록 예측 정확도 높음)\n",
        "    -R^2(결정계수): 실제값 분산과 예측값 분산의 비율 (1에 가까울수록 예측 정확도 높음)  '''\n",
        "# 선형회귀 분석 model에서 학습 데이터에 대한 R^2 구하기\n",
        "print(model.score(X_train, y_train)) # 0.9076\n",
        "# 선형회귀 분석 model에서 테스트 데이터에 대한 R^2 구하기\n",
        "print(model.score(X_test, y_test)) # 0.1073 -> overfitting(과적합) 의심\n",
        "# 결정계수 계산하는 r2_score/ MAE/ MSE 함수 가져오기\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np # 제곱근 계산\n",
        "# 1) 학습 데이터의 R^2 구하기\n",
        "print(r2_score(y_train, y_train_predicted)) # 0.9076\n",
        "# 2) 테스트 데이터의 R^2 구하기\n",
        "print(r2_score(y_test, y_test_predicted)) # 0.1073 \n",
        "# 3) 테스트 데이터의 MSE 구하기\n",
        "print(mean_squared_error(y_test, y_test_predicted)) # 8.8681\n",
        "# 4) 테스트 데이터의 RMSE 구하기\n",
        "print(np.sqrt(mean_squared_error(y_test, y_test_predicted))) # 2.9779\n",
        "# 5) 테스트 데이터의 MAE 구하기\n",
        "print(mean_absolute_error(y_test, y_test_predicted)) # 2.3116\n",
        "\n",
        "\n",
        "''' 2nd) 랜덤 포레스트 회귀 RandomForestRegressor 적합하기\n",
        "        앙상블 모형 중 하나로 무작위의 다수 트리를 만들어 투표로 값 결정 '''\n",
        "# 랜덤 포레스트 회귀: ensemble 모듈에서 RandomForestRegressor 모델 가져오기\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# 랜덤 포레스트 회귀 분석 수행할 모델 만들기\n",
        "model = RandomForestRegressor(random_state=10)\n",
        "# 생성한 모델에 트레이닝 데이터 피팅\n",
        "model.fit(X_train, y_train)\n",
        "# 학습이 완료된 모델에 X_train 전달하여 y_train 값 예측하기\n",
        "y_train_prdicted = model.predict(X_train)\n",
        "# 학습이 완료된 모델에 X_test 전달하여 y_test 값 예측하기\n",
        "y_test_predicted = model.predict(X_test)\n",
        "# R^2/ MSE/ MAE 구하는 함수 일괄로 가져오기\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "# 학습 데이터의 결정계수 구하기\n",
        "print(r2_score(y_train, y_train_predicted)) # 0.9075\n",
        "# 테스트 데이터의 결정계수 구하기\n",
        "print(r2_score(y_test, y_test_predicted)) # 0.3913\n",
        "# 테스트 데이터의 MSE 구하기\n",
        "print(mean_squared_error(y_test, y_test_predicted)) # 6.0463\n",
        "# 테스트 데이터의 MAE 구하기\n",
        "print(mean_absolute_error(y_test, y_test_predicted)) # 1.8203\n",
        "# 테스트 데이터의 RMSE 구하기\n",
        "print(np.sqrt(mean_squared_error(y_test, y_test_predicted))) # 2.4589\n",
        "\n",
        "''' ** 모델 성능 끌어올리기\n",
        "    1) n_estimators: 생성할 트리 개수\n",
        "    2) criterion: 트리 분할 기준(default = mse)     ''' \n",
        "# 트리 생성은 1,000개로, 트리 분할 기준은 MAE 지표로 분석할 모델 만들기\n",
        "model = RandomForestRegressor(n_estimators = 1000, criterion = 'mae', random_state=10)\n",
        "# 기본적인 정보가 담긴 모델에 학습 데이터 학습 시키기\n",
        "model.fit(X_train, y_train)\n",
        "# 학습이 완료된 모델로 y_train 예측하기\n",
        "y_train_predicted = model.predict(X_train)\n",
        "# 학습이 완료된 모델로 y_test 예측하기\n",
        "y_test_predicted = model.predict(X_test)\n",
        "# 결정계수/MSE/ MAE 구하기\n",
        "print(r2_score(y_train, y_train_predicted)) # 0.9809-> 약 0.07 상승\n",
        "print(r2_score(y_test, y_test_predicted)) # 0.4789 -> 0.08 상승\n",
        "print(mean_squared_error(y_test, y_test_predicted)) # 5.1760 -> 0.9 하락\n",
        "print(mean_absolute_error(y_test, y_test_predicted)) # 1.7880 -> 0.67 하락\n",
        "\n",
        "\n",
        "''' 3rd) 그래디언트 부스팅 GradiantBoostingRegressor 적합하기\n",
        "        앙상블 모형 중 하나로 다수의 결정트리를 사용하며,\n",
        "        이전 결정나무에서 발생한 오차를 보완하여 새로운 트리를 만듦 '''\n",
        "# 그래디언트 부스팅 회귀함수 가져오기\n",
        "from sklearn.ensemble import GradientBoostingRegressor        \n",
        "# 하이퍼 파라미터 기본값\n",
        "model = GradientBoostingRegressor(random_state = 10)\n",
        "# 학습 데이터로 모델 학습 후, 예측하기\n",
        "model.fit(X_train, y_train)\n",
        "y_train_predicted = model.predict(X_train)        \n",
        "y_test_predicted = model.predict(X_test)        \n",
        "# 결정계수/ MSE/ MAE 구하기\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score        \n",
        "print(r2_score(y_train, y_train_predicted)) # 0.9999 \n",
        "print(r2_score(y_test, y_test_predicted)) # 0.3303\n",
        "print(mean_squared_error(y_test, y_test_predicted)) # 6.6523\n",
        "print(mean_absolute_error(y_test, y_test_predicted)) # 2.0526\n",
        "\n",
        "\n",
        "''' 4th) 익스트림 그래디언트 부스팅 eXtreme Gradient Boosting(XGB) 적합하기\n",
        "        다수의 약한 분류기를 묶어 정확도를 향상하는 기법.\n",
        "        병렬처리 기능을 지원하여 빠른 속도로 결과 도출 가능 '''\n",
        "# xgboost 라이브러리에서 XGBRegressor 함수 가져오기\n",
        "from xgboost import XGBRegressor\n",
        "# XGBRegressor 함수 호출\n",
        "model = XGBRegressor(random_state=66)\n",
        "# 학습 데이터로 모델 학습 시키고 예측하기\n",
        "model.fit(X_train, y_train)\n",
        "y_train_predicted = model.predict(X_train)\n",
        "y_test_predicted = model.predict(X_test)\n",
        "# R2, MSE, MAE 구하기\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(r2_score(y_train, y_train_predicted)) # 0.9999\n",
        "print(r2_score(y_test, y_test_predicted)) # 0.3000\n",
        "print(mean_squared_error(y_test, y_test_predicted)) # 6.9536\n",
        "print(mean_absolute_error(y_test, y_test_predicted)) # 2.1739\n",
        "\n",
        "\n",
        "## 분류 모델링 수행\n",
        "\n",
        "# am을 종속변수로 바꾸기\n",
        "# X_train 변수에서 종속변수인 am_new 열은 삭제한 후, 결과는 X_train2에 저장\n",
        "X_train2 = X_train.drop(columns = 'am_new')\n",
        "# X_train 변수에서 am_new열을 추출한 후, 종속변수인 y_train2에 저장하기\n",
        "y_train2 = X_train['am_new']\n",
        "# X_test 변수에서 종속변수인 am_new 열은 삭제한 후, 결과는 X_test2에 저장\n",
        "X_test2 = X_test.drop(columns = 'am_new')\n",
        "# X_test 변수에서 am_new열을 추출한 후, 종속변수인 y_test2에 저장하기\n",
        "y_test2 = X_test['am_new']\n",
        "# 데이터 확인\n",
        "print(X_train2.head())\n",
        "print(X_test2.head())\n",
        "print(y_train2.head())\n",
        "print(y_test2.head())\n",
        "\n",
        "''' 1st) 의사결정나무 분류 DecisionTreeClassifier 적합하기\n",
        "        과적합 가능성이 큰 모델.                             '''\n",
        "# tree 모듈에서 제공하는 DecisionTreeClassifier 함수 가져오기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# 의사결정나무 분류 분석 수행할 모델 만들기\n",
        "model = DecisionTreeClassifier()\n",
        "# 생성한 모델에 X_train, y_train 전달하여 의사결정나무 분류 학습\n",
        "model.fit(X_train2, y_train2)\n",
        "# 학습이 완료된 모델로 예측하기\n",
        "y_train2_predicted = model.predict(X_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "\n",
        "''' ** 평가지표\n",
        "    아래 네 지표 모두 1에 가까울수록 성능 좋은 모델!\n",
        "    -roc_auc_score: ROC curve\n",
        "    -accuracy_score(정확도): TP+TN / TP+TN+FP+FN (전체에서 정답 비율)\n",
        "    -precision_score(정밀도): TP / TP+FP (양성으로 예측한 것 중에 찐 양성 비율)\n",
        "    -recall_score(재현율): TP / TP+FN (실제 양성 중 양성 예측한 비율) '''\n",
        "# ROC-AUC/ Accuracy/ Precision/ Recall 계산 위해 metrics 모듈의 함수 가져오기\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "# 테스트 데이터의 roc-auc 구하기\n",
        "print(roc_auc_score(y_test2, y_test2_predicted)) # 0.7619  <- 빅분기 평가지표 **\n",
        "print(accuracy_score(y_test2, y_test2_predicted)) # 0.8\n",
        "print(precision_score(y_test2, y_test2_predicted)) # 0.6666\n",
        "print(recall_score(y_test2, y_test2_predicted)) # 0.6666\n",
        "\n",
        "\n",
        "''' 2nd) 랜덤 포레스트 분류 RandomForestClassifier 적합하기\n",
        "        앙상블 모형 중 하나로 무자구이의 다수 트리를 만들어 투표로 결정 '''\n",
        "# ensemble 모듈에서 RandomForestClassifier 함수 가져오기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# 랜덤 포레스트 분류 분석을 수행할 모델 만들기\n",
        "model = RandomForestClassifier()\n",
        "# 생성한 모델로 학습 시키기\n",
        "model.fit(X_train2, y_train2)\n",
        "# 학습이 완료된 모델로 예측하기\n",
        "y_train2_predicted = model.predict(X_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "# 평가하기\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "print(roc_auc_score(y_train2, y_train2_predicted)) # 1.0\n",
        "print(roc_auc_score(y_test2, y_test2_predicted)) # 0.7619\n",
        "print(accuracy_score(y_test2, y_test2_predicted)) # 0.8\n",
        "print(precision_score(y_test2, y_test2_predicted)) # 0.6666\n",
        "print(recall_score(y_test2, y_test2_predicted)) # 0.6666\n",
        "\n",
        "\n",
        "''' 3rd) 로지스틱 회귀 LogisticRegression 적합하기 '''\n",
        "# linear_model 모듈에서 LogisticRegression 함수 가져오기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# 로지스틱 회귀 분석으로 수행할 모델 만들고 학습하기\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train2, y_train2)\n",
        "# 예측하기\n",
        "y_test2_prediected = model.predict(X_test2)\n",
        "# 평가하기\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "print(roc_auc_score(y_test2, y_test2_predicted)) # 0.7619\n",
        "\n",
        "\n",
        "''' 4th) 익스트림 그래디언트 부스팅 분류(eXtreme Gradient Boosting) XGBClassifier 적합하기\n",
        "        앙상블 모형으로 다수의 약한 분류기를 묶어서 정확도를 향상하는 기법.\n",
        "        병렬처리 지원하여 빠른 속도.                        '''\n",
        "# xgboost 라이브러리에서 제공하는 XGBClassifier 함수 가져오기\n",
        "from xgboost import XGBClassifier\n",
        "# XGB 분류 분석으로 수행할 모델 만들고 학습 시키기\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train2, y_train2)\n",
        "# 예측하기\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "# y_test2_predicted 값 확인하기\n",
        "print(y_test2_predicted)\n",
        "''' ** predict_proba()\n",
        "    종속변수의 분류 값 예측이 아닌, 분류해야 하는 종속변수의 0과 1에 대한 확률값 계산.\n",
        "    즉, 0으로 분류될 확률과 1로 분류될 확률을 각각 계산.\n",
        "    최종적으로 확률이 높은 값을 예측값으로 분류하게 됨 '''\n",
        "# 테스트 데이터의 종속변수에 대한 분류 확률 계산하기\n",
        "y_test2_proba = model.predict_proba(X_test2)\n",
        "# 테스트 데이터에 대한 분류 확률은 y_test2_proba 확인하기\n",
        "print(y_test2_proba) #1열은 0으로 분류될 prob, 2열은 1로 분류될 prob\n",
        "# y_test2_proba를 통해 y_test2_predicted가 결정됨\n",
        "# 예측하기\n",
        "print(roc_auc_score(y_test2, y_test2_predicted)) # 0.7619\n",
        "\n",
        "\n",
        "##### [+] 분류 모델로 사용할 수 있는 기타 알고리즘\n",
        "\n",
        "## 1) 서포트 벡터 머신(SVC: Support Vector Classification)\n",
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train2, y_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "print(roc_auc_score(y_test2, y_test2_predicted)) \n",
        "\n",
        "## 2) 배깅 분류(BaggingClassifier)\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "model = BaggingClassifier()        \n",
        "model.fit(X_train2, y_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "print(roc_auc_score(y_test2, y_test2_predicted))\n",
        "\n",
        "## 3) K-최근접 이웃 분류(KNN: K-Nearest Neighbor)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train2, y_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "print(roc_auc_score(y_test2, y_test2_predicted))\n",
        "\n",
        "## 4) 다층 퍼셉트론 분류(MLPClassifier: Multi Layer Perceptron Classifier)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "model = MLPClassifier()\n",
        "model.fit(X_train2, y_train2)\n",
        "y_test2_predicted = model.predict(X_test2)\n",
        "print(roc_auc_score(y_test2, y_test2_predicted))\n",
        "\n",
        "\n",
        "#--------- <2-4> 최종 결과 공유하기 ---------#\n",
        "\n",
        "##### [1] 결과 출력하기: 제1유형\n",
        "''' 작업형 제1유형은 최종 결과를 print()하는 것. \n",
        "    ** 중간 출력값들은 주석 처리나 삭제해야 함! => 최종 결과만 print~'''\n",
        "\n",
        "\n",
        "##### [2] 결과를 파일에 저장하기: 제2유형\n",
        "''' 작업형 제2유형은 최종 결과를 csv 형식으로 저장하여 제출.\n",
        "    따라서 저장할 파일명, 저장할 경로를 명확히 지정하여 to_csv 함수 사용! '''\n",
        "# 제출할 y_test2_predicted 변수의 데이터 타입 확인하기\n",
        "type(y_test2_predicted) #array\n",
        "# 제출할 변수를 데이터 프레임으로 변경하고, 저장하기\n",
        "pd.DataFrame(y_test2_predicted).to_csv(\"C:/Users/output.csv\", index=False)\n",
        "# ******** index = False는 불필요한 행번호 제외하는 옵션!!!! 꼭 써주기~!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}