{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7MESeEt2fxw03tsPMRLd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeBrave-BeHumble/Coding_test/blob/main/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC_Part4_%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C_%EC%B4%88%EB%B3%B4_%EB%B6%84%EC%84%9D%EA%B0%80_%EB%90%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtzvDVgnNXau"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jun 17 21:19:28 2022\n",
        "\n",
        "@author: FullSun\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "###############################################\n",
        "#####   Part4. 파이썬으로 초보 분석가 되기  #####\n",
        "###############################################\n",
        "''' 작업형 제1유형을 위한 챕터\n",
        "    작업형 제1유형은 데이터 전처리에 초점이 맞추어져 있으며,\n",
        "    주어진 2차원 데이터셋을 가공하여 최종 결과를 print()하면 됨!!\n",
        "    \n",
        "    출력시 중간 출력 결과는 삭제or주석처리 한 후 최종 결과만 print'''\n",
        "    \n",
        "#---------------------------------------------\n",
        "#             1. 단순한 데이터 분석\n",
        "#---------------------------------------------\n",
        "\n",
        "#--------- <1-1> Top10 구하기 ---------#\n",
        "''' Q1. boston data set의 MEDV 칼럼에 대해서 가장 작은 값부터 순서대로\n",
        "        10개 행을 출력. 즉, 오름차순으로 정렬된 MEDV값에서 top 10 구하시오 '''\n",
        "##### 내가 쓴 답안\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/XIUMIN/Desktop/R=VD대기업이직성공/빅데이터 분석기사/bigData-main/boston.csv\")\n",
        "print(pd.DataFrame(sorted(data['MEDV'])).head(10))\n",
        "\n",
        "##### 책 해설\n",
        "import pandas as pd\n",
        "# data 변수 상위 5개 행 출력\n",
        "print(data.head())\n",
        "# sort_values() 함수 사용하여 정렬\n",
        "print(data.sort_values(by = \"MEDV\"))\n",
        "# MEDV 칼럼만 추출\n",
        "print(data.sort_values(by = 'MEDV')['MEDV'])\n",
        "# 상위 10개만 추출\n",
        "print(data.sort_values(by = 'MEDV')['MEDV'].head(10))\n",
        "\n",
        "## 최종 제출 코드\n",
        "import pandas as pd\n",
        "print(data.sort_values(by = 'MEDV')['MEDV'].head(10))\n",
        "\n",
        "\n",
        "#--------- <1-2> 결측치 확인하기 ---------#\n",
        "''' Q2. boston data set의 RM칼럼에 대한 결측치 처리를 평균값으로 대치하거나 삭제할 수 있다.\n",
        "        평균값으로 대치한 후 산출된 표준편차 값과\n",
        "        결측치를 삭제한 후에 산출된 표준편차 값의 차이를 구하시오.\n",
        "        단, 결과값은 양수 '''\n",
        "##### 내 답안\n",
        "data.isnull().sum() # 15개 존재\n",
        "rm_mean1 = data['RM'].mean()\n",
        "RM1 = data['RM'].fillna(rm_mean1)\n",
        "RM2 = data['RM'].dropna()\n",
        "\n",
        "print(RM2.std() - RM1.std()) # 0.010595546094104624\n",
        "\n",
        "##### 책 해설\n",
        "import pandas as pd\n",
        "print(data.isnull()) # data 결측치 여부 확인\n",
        "print(data.isnull().sum())\n",
        "# RM 칼럼 추출 후 data_mean에 저장\n",
        "data_mean = data['RM'].copy()\n",
        "# data_mean 변수에서도 결측치 확인\n",
        "print(data_mean.isnull().sum())\n",
        "# data_mean의 상위 3개 확인\n",
        "print(data_mean.head(3))\n",
        "# data_mean 평균\n",
        "rm_mean = data_mean.mean()\n",
        "print(rm_mean)\n",
        "# data_mean 변경 결과 저장하지 않고 결측치 평균값 대치\n",
        "print(data_mean.fillna(rm_mean, inplace = False)) # inplace=False는 변경 결과를 변수에 반영하지 않는 것.\n",
        "# 변동결과 저장하고 결측치 평균으로 대체\n",
        "data_mean.fillna(rm_mean, inplace = True)\n",
        "# 확인\n",
        "print(data_mean.isnull().sum())\n",
        "# RM 칼럼 추출 후, data_del에 저장\n",
        "data_del = data['RM'].copy()\n",
        "# data_del의 구조 확인\n",
        "print(data_del.shape) # (506,)\n",
        "# data_del의 저장과 함께 결측치 삭제\n",
        "data_del.dropna(inplace = True)\n",
        "# 확인\n",
        "print(data_del.shape) # (491,)\n",
        "# 표준편차 구하기\n",
        "print(data_mean.std())\n",
        "print(data_del.std())\n",
        "# 표준편차 뺀 후 abs() 사용하여 절대값 취하기\n",
        "print(abs( data_mean.std() - data_del.std() )) # 0.010595546094104624\n",
        "\n",
        "## 최종 제출 코드\n",
        "import pandas as pd\n",
        "data_mean = data['RM'].copy()\n",
        "rm_mean = data_mean.mean()\n",
        "data_mean.fillna(rm_mean, inplace=True)\n",
        "data_del = data['RM'].copy()\n",
        "data_del.dropna(inplace=True)\n",
        "\n",
        "print(abs(data_mean.std()-data_del.std()))\n",
        "\n",
        "\n",
        "#--------- <1-3> 이상값 확인하기 ---------#\n",
        "''' Q3. boston의 ZN칼럼을 대상으로 ZN 값의 평균값에서 표준편차의 1.5배보다\n",
        "        크거나 작은 ZN값의 합계를 구하시오 '''\n",
        "##### 내 답안\n",
        "import pandas as pd\n",
        "print(data['ZN'].describe())\n",
        "zn_mean = data['ZN'].mean()\n",
        "zn_std = data['ZN'].std()\n",
        "high = data['ZN'][ data['ZN'] > (zn_mean + 1.5*zn_std) ].sum()\n",
        "low = data['ZN'][ data['ZN'] < (zn_mean - 1.5*zn_std) ].sum()\n",
        "\n",
        "print(high+low) # 3462.5\n",
        "\n",
        "## 내 최종 코드\n",
        "import pandas as pd\n",
        "#print(data['ZN'].describe())\n",
        "zn_mean = data['ZN'].mean()\n",
        "zn_std = data['ZN'].std()\n",
        "high = data['ZN'][ data['ZN'] > (zn_mean + 1.5*zn_std) ].sum()\n",
        "low = data['ZN'][ data['ZN'] < (zn_mean - 1.5*zn_std) ].sum()\n",
        "print(high+low) # 3462.5\n",
        "\n",
        "##### 책 해설\n",
        "import pandas as pd\n",
        "# 평균, 표준편차 구하기\n",
        "zn_mean = data['ZN'].mean()\n",
        "zn_std = data['ZN'].std()\n",
        "# 상한, 하한 구하기\n",
        "zn_max = zn_mean + (1.5 * zn_std)\n",
        "print(zn_max)\n",
        "zn_min = zn_mean - (1.5 * zn_std)\n",
        "print(zn_min)\n",
        "# zn_max 보다 큰 지 여부 확인\n",
        "print(data['ZN'] > zn_max)\n",
        "# ZN 칼럼이 zn_max보다 큰 값들만 확인하기\n",
        "print(data[data['ZN'] > zn_max ])\n",
        "# ZN 칼럼만 추출 후, 해당 데이터를 zn_max2 변수에 저장\n",
        "zn_max2 = data[data['ZN'] > zn_max]['ZN']\n",
        "print(zn_max2)\n",
        "# ZN 칼럼이 zn_min보다 작은 값들만 확인하기\n",
        "print(data[data['ZN'] < zn_min]) # 없음\n",
        "print(sum(zn_max2)) # 3462.5\n",
        "\n",
        "## 최종 제출 코드\n",
        "import pandas as pd\n",
        "zn_mean = data['ZN'].mean()\n",
        "zn_std = data['ZN'].std()\n",
        "zn_max = zn_mean + (1.5 * zn_std)\n",
        "zn_min = zn_min - (1.5 * zn_std)\n",
        "zn_max2 = data[data['ZN'] > zn_max]['ZN']\n",
        "\n",
        "print(sum(zn_max2)) # 3462.5\n",
        "\n",
        "\n",
        "#--------- <1-4> 사분위수 구하기 ---------#\n",
        "''' Q4. boston에서 CHAS 칼럼과 RAD 칼럼을 제외한 칼럼에 한해서\n",
        "        칼럼별 IAR 값을 구하시오.\n",
        "        단, 출력 구조는 2열이고 1열은 보스턴 데이터 세트의 칼럼 이름 '''\n",
        "##### 내 풀이\n",
        "print(data.info()) # 전부 연속형\n",
        "data_IQR = data.drop(columns = ['CHAS', 'RAD'])\n",
        "print(data_IQR.describe().loc['75%'])\n",
        "type(data_IQR.describe().loc['75%'])\n",
        "print(data_IQR.describe().loc['75%'] \\\n",
        "        - data_IQR.describe().loc['25%'])\n",
        "\n",
        "## 내 최종 코드\n",
        "data_IQR = data.drop(columns = ['CHAS', 'RAD'])\n",
        "print( data_IQR.describe().loc['75%'] \\\n",
        "        - data_IQR.describe().loc['25%'] )\n",
        "\n",
        "##### 책 해설\n",
        "print(data.shape)\n",
        "print(data.drop(columns = ['CHAS', 'RAD']))\n",
        "data_col12 = data.drop(columns = ['CHAS', 'RAD'])\n",
        "print(data_col12.shape)\n",
        "# 기초통계량 저장하기\n",
        "data_col12_desc = data_col12.describe()\n",
        "print(data_col12_desc)\n",
        "# 4번행, 6번행 가져오기\n",
        "print(data_col12_desc.iloc[[4,6]]) # 한번 감싸면 4행 6열\n",
        "# 행렬 구조 변환\n",
        "print(data_col12_desc.iloc[[4,6]].T)\n",
        "# 행렬 구조 변환한 데이터 저장하기\n",
        "data_col12_desc_T = data_col12_desc.iloc[[4,6]].T\n",
        "print(data_col12_desc_T) # DF\n",
        "# IQR 구하기\n",
        "print(data_col12_desc_T['75%'] - data_col12_desc_T['25%'])\n",
        "\n",
        "## 최종 제출 코드\n",
        "data_col12 = data.drop(columns = ['CHAS', 'RAD'])\n",
        "data_col12_desc = data_col12.describe()\n",
        "data_col12_desc_T = data_col12_desc.iloc[[4,6]].T\n",
        "print(data_col12_desc_T['75%'] - data_col12_desc_T['25%'])\n",
        "\n",
        "\n",
        "#--------- <1-5> 순위 구하기 ---------#\n",
        "''' Q5. boston set의 MEDV 칼럼을 기준으로 30번째로 큰 값을\n",
        "        1~29번째로 큰 값에 적용한다.\n",
        "        그리고 MEDV 칼럼의 mean, median, min, max을 한 줄에 출력하시오. '''\n",
        "\n",
        "##### 내 풀이\n",
        "data_MEDV = data['MEDV']\n",
        "print( data_MEDV.sort_values(ascending = False) ) #시리즈라 by 안 씀\n",
        "data_MEDV2 = pd.DataFrame( data_MEDV.sort_values(ascending = False) )\n",
        "print( data_MEDV2.iloc[29] ) # 0부터니까 idx29가 30번째로 큰 값..\n",
        "print( data_MEDV2[0:29] ) # 1~29번째로 큰 값 (range는 끝번호-1 주의!!!!!)\n",
        "data_MEDV2[0:29] = 41.7\n",
        "print(data_MEDV2) #확인\n",
        "#print( data_MEDV2.mean(), data_MEDV2.std(), data_MEDV2.min(), data_MEDV2.max())\n",
        "# 위처럼 쓰면 한 줄에 출력이 안 됨\n",
        "\n",
        "print( data_MEDV2.mean()[0], data_MEDV2.std()[0], data_MEDV2.min()[0], data_MEDV2.max()[0])\n",
        "#뭐지,, 시리즈 상태에서 뭐가 안 돼서 DF로 바꿨는데 책 해설 보니 되네.. 쩝\n",
        "\n",
        "## 내 최종 코드\n",
        "data_MEDV = data['MEDV']\n",
        "data_MEDV2 = pd.DataFrame( data_MEDV.sort_values(ascending = False) )\n",
        "data_MEDV2[0:28] = data_MEDV2.iloc[29]\n",
        "print( data_MEDV2.mean()[0], data_MEDV2.std()[0], data_MEDV2.min()[0], data_MEDV2.max()[0])\n",
        "\n",
        "##### 책 해설\n",
        "print(data['MEDV'].head(3))\n",
        "data_new = data['MEDV'].sort_values(ascending = False)\n",
        "print(data_new.head(30))\n",
        "print(data_new.iloc[29]) #30번째로 큰 값\n",
        "print(data_new.iloc[0:29]) # range는 끝번호-1\n",
        "data_new.iloc[0:29] = 41.7\n",
        "print(data_new.iloc[0:29])\n",
        "print(data_new.mean(), data_new.std(), data_new.min(), data_new.max())\n",
        "\n",
        "## 최종 제출 코드\n",
        "data_new = data['MEDV'].sort_values(ascending = False)\n",
        "data_new.iloc[0:29] = 41.7\n",
        "print(data_new.mean(), data_new.std(), data_new.min(), data_new.max())\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------\n",
        "#             2. 복잡한 데이터 분석\n",
        "#---------------------------------------------\n",
        "\n",
        "#--------- <2-1> 그룹별 집계/요약하기 ---------#\n",
        "''' Q1. boston 데이터셋의 TAX 칼럼이 TAX 칼럼의 중위값보다 큰 데이터를 대상으로,\n",
        "        CHAS 칼럼과 RAD 칼럼 순으로 그룹을 지은 후 \n",
        "        각 그룹의 데이터 개수를 구하시오. 단 CHAS,RAD 칼럼별 데이터 개수는\n",
        "        COUNT라는 칼럼으로 출력합니다.\n",
        "        \n",
        "        ** groupby 함수 문법\n",
        "        DataFrame.groupby([그룹화할 컬럼]).[수행할 컬럼].수행할 작업()\n",
        "        그룹화할 컬럼으로 그룹을 만든 후, 수행할 컬럼으로 추가 작업 수행.'''\n",
        "\n",
        "##### 내 풀이\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"C:/Users/XIUMIN/Desktop/R=VD대기업이직성공/빅데이터 분석기사/bigData-main/boston.csv\")\n",
        "data.head()\n",
        "data.info()\n",
        "\n",
        "print(data.median().loc['TAX'])\n",
        "data_TAX = data[data['TAX']>330.0]\n",
        "print(data_TAX.loc[:,['CHAS', 'RAD']]) # = data_TAX[['CHAS', 'RAD']]\n",
        "print(data_TAX.groupby(['CHAS', 'RAD']).count())\n",
        "\n",
        "## 내 최종 코드\n",
        "#print(data.median().loc['TAX'])\n",
        "data_TAX = data[data['TAX']>330.0]\n",
        "print(data_TAX.groupby(['CHAS', 'RAD']).count())\n",
        "'''  ============== 틀림!! 이유: 문제 이해를 잘못함 ============== '''\n",
        "\n",
        "##### 책 해설\n",
        "tax_median = data['TAX'].median()\n",
        "print(tax_median)\n",
        "print(data['TAX'] > tax_median) # TAX칼럼에서 중위값보다 큰 지 확인. False/True로 표시됨\n",
        "print(data[data['TAX'] > tax_median]) # True인 값 추출\n",
        "print(data[data['TAX'] > tax_median][['CHAS', 'RAD']]) # CHAS, RAD열 추출\n",
        "data_new = data[data['TAX']> tax_median][['CHAS', 'RAD']]\n",
        "# grouping 전 CHAS 칼럼에 있는 데이터 종류 확인하기\n",
        "print(data_new['CHAS'].unique()) # [0, 1]\n",
        "print(data_new['RAD'].unique()) # [ 3  4  5  6  2  1 24]\n",
        "''' 이번 문제에서는 CHAS 칼럼과 RAD칼럼으로 그룹화한 결과에 count만 수행하면 되므로\n",
        "    RAD칼럼이나 CHAS 칼럼 둘 중 어떤 거로 수행해도 결과는 동일함 '''\n",
        "data_new2 = data_new.groupby(['CHAS', 'RAD'])['RAD'].count()\n",
        "print(data_new2)\n",
        "data_new.groupby(['CHAS', 'RAD'])['CHAS'].count() # 결과 같음\n",
        "# 비어있는 칼럼 이름에 count 채우기\n",
        "print(type(data_new2)) # 시리즈 -> 1개의 칼럼만을 가지고 있다는 뜻!!\n",
        "# Series를 DF로 변환하여 칼럼 이름 변경\n",
        "data_new3 = pd.DataFrame(data_new2)\n",
        "data_new3.columns = ['COUNT']\n",
        "\n",
        "## 최종 제출 코드\n",
        "tax_median = data['TAX'].median()\n",
        "data[data['TAX'] > tax_median]\n",
        "data_new = data[data['TAX'] > tax_median][['CHAS', 'RAD']]\n",
        "data_new2 = data_new.groupby(['CHAS', 'RAD'])['RAD'].count()\n",
        "data_new3 = pd.DataFrame(data_new2)\n",
        "data_new3.columns = ['COUNT']\n",
        "print(data_new3)\n",
        "\n",
        "\n",
        "#--------- <2-2> 오름차순/ 내림차순 정렬하기 ---------#\n",
        "\n",
        "''' Q2. boston 데이터셋의 TAX 칼럼을 오름차순으로 정렬한 결과와 내림차순으로\n",
        "        정렬한 결과를 각각 구한다. 그리고 각 순번에 맞는 오름차순 값과\n",
        "        내림차순 값의 차이를 구하여 분산 값을 출력하시오.\n",
        "        \n",
        "        ** concat 함수 문법\n",
        "        pd.concat([데이터프레임1, 데이터프레임2], axis = 합칠 기준) '''\n",
        "\n",
        "'''  ============== 틀림!! 이유: 절대값^^,, ============== '''\n",
        "##### 내 풀이\n",
        "print(data.sort_values(by = 'TAX')) # 오름차순\n",
        "print(data.sort_values(by = 'TAX', ascending = False)) # 내림차순\n",
        "data_asc = data.sort_values('TAX', ignore_index = True) \n",
        "data_desc = data.sort_values(by = 'TAX', ascending = False, ignore_index = True)\n",
        "print(data_asc['TAX'] - data_desc['TAX'])\n",
        "''' sort_value하면 index가 다시 매겨지는 것이 아니기 때문에\n",
        "    data_acs - data_desc 하면 전부 0으로 출력됨.\n",
        "    사칙연산은 같은 인덱스(위치)끼리 계산되기 때문에,\n",
        "    따라서 ignore_index = True 옵션을 주어 랭크에 따라 index를 다시 매겨줌 '''\n",
        "#print( ( data_asc['TAX'] - data_desc['TAX']     ).var() ) # 101954.72\n",
        "print( abs( data_asc['TAX'] - data_desc['TAX']     ).var() )\n",
        "\n",
        "## 내 최종 코드\n",
        "data_asc = data.sort_values('TAX', ignore_index = True)\n",
        "data_desc = data.sort_values('TAX', ascending = False, ignore_index = True)\n",
        "#print( ( data_asc['TAX'] - data_desc['TAX'] ).var() ) # 101954.72\n",
        "print(  abs( data_asc['TAX'] - data_desc['TAX']     ).var() )\n",
        "\n",
        "##### 책 해설\n",
        "data_asc = data['TAX'].copy()\n",
        "data_desc = data[['TAX']].copy()\n",
        "print(data_asc.sort_values(ascending = True))\n",
        "# 정렬된 데이터를 저장하기\n",
        "data_asc.sort_values(inplace = True)\n",
        "data_desc.sort_values(ascending = False, inplace = True)\n",
        "# 뒤섞인 인덱스 재설정하기\n",
        "data_asc.reset_index(drop = True, inplace = True) # drop=True : 원래 인덱스 삭제\n",
        "data_desc.reset_index(drop = True, inplace = True)\n",
        "# 두 데이터셋을 칼럼 기준으로 통합하기\n",
        "data_concat = pd.concat([data_asc, data_desc], axis = 1) # axis=1: 열기준, axis=0: 행기준\n",
        "print(data_concat)\n",
        "print(data_concat.iloc[:, 0]) # 첫 번째 열 추출\n",
        "print(data_concat.iloc[:, 1]) # 두 번째 열 추출\n",
        "# difference 구한 후 >절대값< 구하여 세 번째 열로 저장\n",
        "data_concat['diff'] = abs(data_concat.iloc[:, 0] - data_concat.iloc[:, 1])\n",
        "print(data_concat)\n",
        "print(data_concat['diff'].var()) # 분산 구하기\n",
        "\n",
        "## 최종 제출 코드\n",
        "data_asc = data['TAX'].copy()\n",
        "data_desc = data['TAX'].copy()\n",
        "data_asc.sort_values(inplace = True)\n",
        "data_desc.sort_values(ascending = False, inplace = True)\n",
        "data_asc.reset_index(drop = True, inplace = True)\n",
        "data_desc.reset_index(drop = True, inplace = True)\n",
        "data_concat = pd.concat([data_asc, data_desc], axis = 1)\n",
        "data_concat['diff'] = abs( data_concat.iloc[:, 0] - data_concat.iloc[:, 1] )\n",
        "print( data_concat['diff'].var() )\n",
        "\n",
        "\n",
        "#--------- <2-3> 최소최대 변환하기 ---------#\n",
        "''' Q3. boston의 MEDV 칼럼을 최소최대 척도로 변환한 후 0.5보다 큰 값을 가지는\n",
        "    레코드 수를 구하시오. '''\n",
        "\n",
        "##### 내 풀이\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "print(scaler.fit_transform(data[['MEDV']]))\n",
        "data_MEDV = scaler.fit_transform(data[['MEDV']])\n",
        "data_MEDV2 = pd.DataFrame(data_MEDV) \n",
        "data_MEDV2.columns = ['MEDV_new']\n",
        "print( data_MEDV2[ data_MEDV2['MEDV_new'] > 0.5 ].count() )\n",
        "\n",
        "## 내 최종 코드\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_MEDV = scaler.fit_transform(data[['MEDV']])\n",
        "data_MEDV2 = pd.DataFrame(data_MEDV)\n",
        "data_MEDV2.columns = ['MEDV_new']\n",
        "print( data_MEDV2[ data_MEDV2['MEDV_new'] > 0.5 ]['MEDV_new'].count() )\n",
        "\n",
        "##### 책 해설\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_minmax = scaler.fit_transform(data) # 모든 변수를 각각 스케일링\n",
        "print(type(data_minmax))\n",
        "data_minmax = pd.DataFrame(data_minmax, columns = data.columns)\n",
        "# columns = data.columns 옵션: data의 column을 그대로 사용하기 위해\n",
        "print(data_minmax.head(3))\n",
        "print(data_minmax['MEDV'].describe()) # 기초통계량 확인 => min~max : 0~1\n",
        "print(data_minmax['MEDV'] > 0.5) # True/ False\n",
        "print(data_minmax[data_minmax['MEDV'] > 0.5]) # True값만 출력\n",
        "print(data_minmax[data_minmax['MEDV'] > 0.5]['MEDV']) # True인 MEDV열만 출력\n",
        "# 0.5 초과하는 MEDV 값의 개수 세기\n",
        "print(data_minmax[data_minmax['MEDV'] > 0.5]['MEDV'].count())\n",
        "\n",
        "## 최종 제출 코드\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_minmax = scaler.fit_transform(data)\n",
        "data_minmax = pd.DataFrame(data_minmax, columns = data.columns)\n",
        "print(data_minmax[ data_minmax['MEDV'] > 0.5]['MEDV'].count() )\n",
        "\n",
        "\n",
        "#--------- <2-4> 빈도값 구하기 ---------#\n",
        "''' Q4. boston 데이터셋의 AGE 칼럼을 소수점 첫 번째 자리에서 반올림하고,\n",
        "        가장 많은 비중을 차지하는 AGE 값과 그 개수를 차례대로 출력하시오.\n",
        "        즉, AGE 칼럼의 최빈값과 그 개수를 출력하시오. '''\n",
        "\n",
        "##### 내 풀이\n",
        "print(data.head()['AGE'])\n",
        "print(round(data['AGE'], 0))\n",
        "data_round = round(data[['AGE']], 0)\n",
        "print(type(data_round)) # DF\n",
        "print(data_round.groupby(['AGE'])['AGE'].count())\n",
        "data_round2 = pd.DataFrame(data_round.groupby(['AGE'])['AGE'].count().sort_values())\n",
        "data_round2.columns = ['COUNT']\n",
        "print('최빈값:', data_round2.index[-1], 'count:', data_round2['COUNT'].iloc[-1])\n",
        "\n",
        "## 내 최종 코드\n",
        "data_round = round(data[['AGE']], 0)\n",
        "data_round2 = pd.DataFrame(data_round.groupby(['AGE'])['AGE'].count().sort_values())\n",
        "data_round2.columns = ['COUNT']\n",
        "print('최빈값:', data_round2.index[-1], 'count:', data_round2['COUNT'].iloc[-1])\n",
        "\n",
        "##### 책 해설 \n",
        "##### 방법 1)\n",
        "print(data['AGE'])\n",
        "print(round(data['AGE'], 0))\n",
        "data2 = round(data['AGE'], 0)\n",
        "data2 = pd.DataFrame(data2) # Series -> DF 변경\n",
        "# AGE로 그룹화 하고, 그룹별 AGE 칼럼 수 세기\n",
        "print(data2.groupby(['AGE'])['AGE'].count())\n",
        "data3 = data2.groupby(['AGE'])['AGE'].count()\n",
        "print(data3) # AGE칼럼 기준으로 데이터가 정렬되어 있고, 칼럼의 빈도수가 섞여있음\n",
        "print(type(data3)) # 시리즈\n",
        "data3 = pd.DataFrame(data3) # Series -> DF 변경\n",
        "print(type(data3))\n",
        "# data3 변수의 칼럼 이름 확인하기\n",
        "print(data3.columns)  # col이름이 인덱스인 AGE와 동일하므로 변경 필요\n",
        "data3.columns = ['COUNT']\n",
        "print(data3.head())\n",
        "# 기존 AGE인덱스를 칼럼으로 사용하고, 새로운 index 부여하기\n",
        "data3.reset_index(drop = False, inplace = True)\n",
        "print(data3.head())\n",
        "''' ** reset_index\n",
        "    - drop=False : 기존 AGE 인덱스를 삭제하지 않고 칼럼으로 만듦\n",
        "    - inplace=True : data3에 즉시 저장 '''\n",
        "# 내림차순 정렬\n",
        "data3.sort_values(by = 'COUNT', ascending = False, inplace = True)\n",
        "print(data3.head())\n",
        "# 최빈값과 개수 출력하기\n",
        "print(data3.iloc[0,0], data3.iloc[0,1])\n",
        "\n",
        "\n",
        "##### 방법 2)\n",
        "from scipy.stats import mode\n",
        "data2 = round(data['AGE'], 0)\n",
        "print(mode(data2)) # ModeResult(mode=array([100.]), count=array([43]))\n",
        "# 최빈값은 100이고, 개수는 43\n",
        "print(mode(data2)[0], mode(data2)[1]) # 숫자만 출력하기\n",
        "print(type(mode(data2)[0])) #ndarray\n",
        "# 숫자만 남기기 위해, 정수형으로 변환하여 데이터 타입 변환\n",
        "print(int(mode(data2)[0]))\n",
        "print(int(mode(data2)[1]))\n",
        "print( int(mode(data2)[0]), int(mode(data2)[1]) )\n",
        "\n",
        "## 최종 제출 코드\n",
        "from scipy.stats import mode\n",
        "print( int(mode( round(data['AGE'], 0) )[0]) ,\n",
        "      int(mode( round(data['AGE'], 0) )[1]) )\n",
        "\n",
        "\n",
        "#--------- <2-5> 표준 변환하기 ---------#\n",
        "''' Q5. boston 데이터셋의 DIS 칼럼을 표준화 척도로 변환 후,\n",
        "        0.4보다 크면서 0.6보다 작은 값들에 대한 평균을 구하시오.\n",
        "        단, 소수점 셋째자리에서 반올림하여 소수점 둘째 자리까지 출력하시오. '''\n",
        "\n",
        "##### 내 풀이\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scale = scaler.fit_transform(data)\n",
        "data_scale = pd.DataFrame(data_scale, columns = data.columns)\n",
        "print(data_scale.describe())\n",
        "data_cut = data_scale[ data_scale['DIS'] > 0.4 ]\n",
        "data_cut = data_cut[ data_cut['DIS'] < 0.6 ]\n",
        "# ** => print( data[ (data['DIS'] > 0.4) & (data['DIS'] < 0.6) ] )\n",
        "print( round( data_cut['DIS'].mean(), 2 ) )\n",
        "\n",
        "## 내 최종 코드\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scale = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)\n",
        "#print(data_scale.describe()['DIS'])\n",
        "data_scale = data_scale[ data_scale['DIS'] > 0.4 ]\n",
        "data_scale = data_scale[ data_scale['DIS'] < 0.6 ]\n",
        "print( round( data_scale['DIS'].mean() ,2) )\n",
        "\n",
        "##### 책 해설\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_stdd = scaler.fit_transform(data)\n",
        "print(type(data_stdd))\n",
        "data_stdd = pd.DataFrame(data_stdd, columns = data.columns)\n",
        "print( (data_stdd['DIS'] > 0.4) & (data_stdd['DIS'] < 0.6 ))\n",
        "# data_stdd 변수의 DIS 칼럼이 0.4~0.6인 값 출력하기\n",
        "print(data_stdd[ (data_stdd['DIS'] > 0.4) & (data_stdd['DIS'] < 0.6) ])\n",
        "data_stdd = data_stdd[ (data_stdd['DIS'] > 0.4) & (data_stdd['DIS'] < 0.6) ]\n",
        "print(data_stdd['DIS'].mean())\n",
        "print( round(data_stdd['DIS'].mean(), 2) )\n",
        "\n",
        "## 최종 제출 코드\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_stdd = scaler.fit_transform(data)\n",
        "data_stdd = pd.DataFrame(data_stdd, columns = data.columns)\n",
        "data_stdd = data_stdd[ (data_stdd['DIS'] > 0.4) & (data_stdd['DIS'] < 0.6) ]\n",
        "print( round( data_stdd['DIS'].mean(), 2 ) )\n",
        "\n",
        "\n",
        "#--------- <2-6> 유니크한 값 구하기 ---------#\n",
        "''' Q6. boston 데이터셋의 전체 칼럼에 대해서 중복을 제거한 유니크한 값을 구한 후,\n",
        "        칼럼별로 유니크한 값의 개수를 기준으로 평균값을 구하시오. '''\n",
        "\n",
        "##### 내 답안\n",
        "print(data.columns.size) # data의 column 수 구하기 <- 분모\n",
        "# 14개의 열이 있음. => col인덱싱은 0~13이 됨. 13-0+1=14\n",
        "a = []\n",
        "\n",
        "for i in range(0, data.columns.size) :\n",
        "    #range(0,14)인데 끝번호 -1이니까 0~13까지 돌아감.\n",
        "    a.append(data.groupby(data.columns[i])[data.columns[i]].count().size)\n",
        "print(a)\n",
        "print(sum(a) / data.columns.size)\n",
        "\n",
        "## 내 최종 코드\n",
        "#print(data.columns.size)\n",
        "a = []\n",
        "for i in range(0, data.columns.size) :\n",
        "    a.append( data.groupby([data.columns[i]])[data.columns[i]].count().size )\n",
        "print( sum(a)/ data.columns.size )                            \n",
        "    \n",
        "##### 책 해설\n",
        "##### 방법 1)\n",
        "print(data.columns) # 칼럼 목록 확인\n",
        "data_col = data.columns # 칼럼 저\n",
        "print(data_col.size) # 칼럼 수 확인\n",
        "print(data['CHAS'].unique()) \n",
        "print(pd.DataFrame(data['CHAS'].unique())) # DF로 변환\n",
        "print(pd.DataFrame(data['CHAS'].unique()).count())\n",
        "# ㄴ 건수 확인 -> 0    2 -> 2건이란 뜻. 0은 인덱스\n",
        "print( int( pd.DataFrame( data['CHAS'].unique() ).count() ) )\n",
        "# 2건이라는 값만 추출하기 위해 데이터 타입을 int로 변경 !!\n",
        "# pd.DataFrame( data['CHAS'].unique() ).count()[0] \n",
        "\n",
        "# 14개의 칼럼에 같은 작업 반복\n",
        "print( \n",
        "      ( int(pd.DataFrame( data.groupby(['CRIM'])['CRIM'].unique() ).count()) +\n",
        "        int(pd.DataFrame( data.groupby(['ZN'])['ZN'].unique() ).count()) +\n",
        "        int(pd.DataFrame( data.groupby(['INDUS'])['INDUS'].unique()).count())+\n",
        "        int(pd.DataFrame( data.groupby(['CHAS'])['CHAS'].unique() ).count()) +\n",
        "        int(pd.DataFrame( data.groupby(['NOX'])['NOX'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['RM'])['RM'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['AGE'])['AGE'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['DIS'])['DIS'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['RAD'])['RAD'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['TAX'])['TAX'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['PTRATIO'])['PTRATIO'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['B'])['B'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['LSTAT'])['LSTAT'].unique() ).count() ) +\n",
        "        int(pd.DataFrame( data.groupby(['MEDV'])['MEDV'].unique() ).count() )\n",
        "       ) / data.columns.size\n",
        "      )\n",
        "      \n",
        "##### 방법 2)\n",
        "data_col = data.columns\n",
        "sum = 0\n",
        "for i in data_col:\n",
        "    sum = sum + int( pd.DataFrame(data.groupby([i])[i].unique() ).count() )\n",
        "    \n",
        "print(sum)\n",
        "print(sum / data.columns.size)\n",
        "\n",
        "## 최종 제출 코드\n",
        "data_col = data.columns\n",
        "sum = 0\n",
        "for i in data_col:\n",
        "    sum = sum + int( pd.DataFrame(data.groupby([i])[i].unique()).count() )    \n",
        "print( sum / data.columns.size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}