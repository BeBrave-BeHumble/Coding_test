{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTvkTp457ebXY1rNMHa0AS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeBrave-BeHumble/Coding_test/blob/main/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC_3%ED%9A%8C%EC%8B%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUg7kX0cUaA4"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Jun 25 05:40:59 2022\n",
        "\n",
        "@author: FullSun\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#---------------------------------------------\n",
        "#               작업형 제 1유형\n",
        "#---------------------------------------------\n",
        "\n",
        "#----------- [1-1] -----------#\n",
        "import pandas as  pd\n",
        "data = pd.read_csv('C:/Users/3rd_boston_housing.csv')\n",
        "print(data.describe().T)\n",
        "print(506*0.7)\n",
        "print(data.isnull().sum())\n",
        "data = data.dropna()\n",
        "data = data.iloc[:int(len(data)*0.7), :]\n",
        "print(data.describe().T.loc['tax', '25%'])\n",
        "\n",
        "# 최종코드\n",
        "import pandas as  pd\n",
        "data = pd.read_csv('C:/Users/3회실기/3rd_boston_housing.csv')\n",
        "data = data.dropna()\n",
        "data = data.iloc[:int(len(data)*0.7), :]\n",
        "print(data.describe().T.loc['tax', '25%'])\n",
        "\n",
        "\n",
        "#----------- [1-2] -----------#\n",
        "import pandas as pd\n",
        "data = pd.read_csv('C:/Users/3회실기/3rd_tour.csv', encoding='cp949', index_col='year')\n",
        "print(data.head(3).T)\n",
        "print(data.describe().T)\n",
        "#2000년도 전체 입국자 평균\n",
        "mean_2000 = data[data['year'] == 2000].T.loc['중국':'아프리카 기타'].mean(axis=0)\n",
        "print(pd.DataFrame((data[data['year']==2000].T > mean_2000).sum()).iloc[0,0])\n",
        "\n",
        "## 책 해설\n",
        "import pandas as pd\n",
        "data = pd.read_csv('C:/Users/XIUMIN/', index_col='year')\n",
        "mean_2000 = data.loc[2000].mean()\n",
        "print((data.loc[2000,:]>mean_2000).sum())\n",
        "\n",
        "#----------- [1-3] -----------#\n",
        "import pandas as pd\n",
        "data=pd.read_csv('C:/Users/3회실기/3rd_titanic.csv')\n",
        "print(data.describe().T)\n",
        "print(data.isnull().sum())\n",
        "dd = pd.DataFrame(data.isnull().sum()).reset_index(drop=False).sort_values(by=0,ascending=False)\n",
        "print(dd.iloc[0,0])\n",
        "\n",
        "###\n",
        "print((data.isnull().sum()/len(data)).sort_values(ascending=False).index[0])\n",
        "data\n",
        "\n",
        "\n",
        "#---------------------------------------------\n",
        "#               작업형 제 2유형\n",
        "#---------------------------------------------\n",
        "import time\n",
        "start=time.time()\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "X_train = pd.read_csv('C:/Users/3회실기/3rd_TravelInsurancePrediction_train.csv')\n",
        "X_test = pd.read_csv('C:/Users/3회실기/3rd_TravelInsurancePrediction_test.csv')\n",
        "print(X_test.describe().T)\n",
        "print(X_train.describe().T)\n",
        "\n",
        "# y 쪼개기\n",
        "y_train = X_train['TravelInsurance']\n",
        "X_train = X_train.drop(columns=['ID', 'TravelInsurance'])\n",
        "X_test_id = X_test['ID']\n",
        "X_test = X_test.drop(columns=['ID'])\n",
        "\n",
        "# 데이터 확인\n",
        "print(X_train.head(3).T)\n",
        "''' Employment Type \n",
        "    GraduateOrNot\n",
        "    FrequentFlyer   \n",
        "    EverTravelledAbroad '''\n",
        "X_train_cate = X_train[['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']]\n",
        "X_test_cate = X_test[['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']]\n",
        "\n",
        "X_train_conti = X_train.drop(columns = ['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad'])\n",
        "X_test_conti = X_test.drop(columns = ['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad'])\n",
        "\n",
        "data = pd.concat([y_train, X_train_conti, X_train_cate], axis=1)\n",
        "\n",
        "# 범주형 정리\n",
        "print (X_train_cate['Employment Type'].unique(), '\\n',\n",
        "       X_train_cate['GraduateOrNot'].unique(), '\\n',\n",
        "       X_train_cate['FrequentFlyer'].unique(), '\\n',\n",
        "       X_train_cate['EverTravelledAbroad'].unique(), '\\n')\n",
        "from pandas import get_dummies\n",
        "X_train_cate = pd.get_dummies(X_train_cate, drop_first=True)\n",
        "X_test_cate = pd.get_dummies(X_test_cate, drop_first=True)\n",
        "X_train_cate, X_test_cate = X_train_cate.align(X_test_cate, join=\"inner\", axis=1)\n",
        "print(X_train_cate.shape, X_test_cate.shape)\n",
        "\n",
        "print(data.groupby(['Employment Type'])['TravelInsurance'].count(),\n",
        "      data.groupby(['GraduateOrNot'])['TravelInsurance'].count(),\n",
        "      data.groupby(['FrequentFlyer'])['TravelInsurance'].count(),\n",
        "      data.groupby(['EverTravelledAbroad'])['TravelInsurance'].count())\n",
        "\n",
        "# 연속형 정리\n",
        "print(X_train_conti.describe())\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_conti = pd.DataFrame(scaler.fit_transform(X_train_conti), columns=X_train_conti.columns)\n",
        "X_test_conti = pd.DataFrame(scaler.transform(X_test_conti), columns=X_test_conti.columns)\n",
        "X_train_conti.columns\n",
        "print(data[['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases','TravelInsurance']].corr())\n",
        "\n",
        "# 스플릿\n",
        "X_train = pd.concat([X_train_conti, X_train_cate], axis=1)\n",
        "X_test = pd.concat([X_test_conti, X_test_cate], axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "\n",
        "roc_list = []\n",
        "\n",
        "for a in range(0,20) :\n",
        "\n",
        "    X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train, y_train,\n",
        "                                                          test_size=0.2, stratify=y_train,\n",
        "                                                          random_state=a)\n",
        "\n",
        "    model1 = XGBClassifier(n_estimators=100, max_depth=3, random_state=66)\n",
        "    model2 = XGBClassifier(n_estimators=200, max_depth=5, random_state=66)\n",
        "    model3 = RandomForestClassifier(criterion='entropy', max_depth=8, random_state=66)        \n",
        "    model4 = RandomForestClassifier(criterion='entropy', max_depth=10, random_state=66)        \n",
        "\n",
        "    model1.fit(X_train1, y_train1)\n",
        "    model2.fit(X_train1, y_train1)\n",
        "    model3.fit(X_train1, y_train1)\n",
        "    model4.fit(X_train1, y_train1)\n",
        "\n",
        "    y_val_pred1 = pd.DataFrame(model1.predict(X_val1)).rename(columns={0:'pred'})\n",
        "    y_val_pred2 = pd.DataFrame(model2.predict(X_val1)).rename(columns={0:'pred'})\n",
        "    y_val_pred3 = pd.DataFrame(model3.predict(X_val1)).rename(columns={0:'pred'})\n",
        "    y_val_pred4 = pd.DataFrame(model4.predict(X_val1)).rename(columns={0:'pred'})\n",
        "\n",
        "    roc1 = roc_auc_score(y_val1, y_val_pred1)\n",
        "    roc2 = roc_auc_score(y_val1, y_val_pred2)\n",
        "    roc3 = roc_auc_score(y_val1, y_val_pred3)\n",
        "    roc4 = roc_auc_score(y_val1, y_val_pred4)\n",
        "    \n",
        "    roc_list.append((a, roc1, roc2, roc3, roc4))\n",
        "\n",
        "roc_list2 = pd.DataFrame(roc_list)\n",
        "print(roc_list2[1].max(), roc_list2[2].max(), roc_list2[3].max(), roc_list2[4].max())\n",
        "print(roc_list2[1].argmax())\n",
        "print(roc_list2.iloc[15,])\n",
        "\n",
        "print(time.time()-start)\n"
      ]
    }
  ]
}